{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:58:00.636151Z",
     "start_time": "2024-12-10T16:58:00.607286Z"
    }
   },
   "cell_type": "code",
   "source": "import polars as pl",
   "id": "b233267874d5bc8e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:09:54.582816Z",
     "start_time": "2024-12-09T17:09:54.581015Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "50d98a180ae3ce62",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:04.720109Z",
     "start_time": "2024-12-09T17:06:04.718437Z"
    }
   },
   "cell_type": "code",
   "source": "path = \"/home/richardarcher/.cache/kagglehub/datasets/yelp-dataset/yelp-dataset/versions/4/\"",
   "id": "91a84f607167e13b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:05.194923Z",
     "start_time": "2024-12-09T17:06:05.193083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_reviews = path+\"yelp_academic_dataset_review.json\"\n",
    "# path_businesses = path+\"yelp_academic_dataset_business.json\"\n",
    "# path_tips = path+\"yelp_academic_dataset_tip.json\"\n",
    "# path_checkins = path+\"yelp_academic_dataset_checkin.json\"\n",
    "path_users = path+\"yelp_academic_dataset_user.json\""
   ],
   "id": "3a801884387aaf20",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:06.256090Z",
     "start_time": "2024-12-09T17:06:06.252370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_json_to_dataframe(json_path, max_to_import=999_999_999):\n",
    "    \"\"\"\n",
    "    Load a JSON file with line-delimited JSON objects into a Polars DataFrame, \n",
    "    with an option to limit the number of rows imported. Convert all spaces to \n",
    "    proper spaces and ensure no NBSP remain.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_line(line):\n",
    "        # Normalize unicode to ensure consistency in whitespace representations\n",
    "        line = unicodedata.normalize(\"NFKC\", line)\n",
    "        \n",
    "        # Replace various forms of non-breaking spaces and related entities with a normal space\n",
    "        # '\\u00a0' is the standard NBSP unicode character\n",
    "        # '&nbsp;' is an HTML entity that may appear\n",
    "        # We'll also remove literal 'NBSP' if present as text.\n",
    "        line = line.replace(\"\\u00a0\", \" \")\n",
    "        line = line.replace(\"\\xa0\", \" \")  # Sometimes NBSP is represented like this\n",
    "        line = line.replace(\"&nbsp;\", \" \")\n",
    "        line = line.replace(\"NBSP\", \" \")\n",
    "        \n",
    "        return line\n",
    "\n",
    "    # Read and clean each line before parsing\n",
    "    data = []\n",
    "    errors = 0\n",
    "    with open(json_path, 'r', encoding='utf-8') as data_file:\n",
    "        for line in data_file:\n",
    "            try:\n",
    "                clean_data = json.loads(clean_line(line))\n",
    "            except:\n",
    "                # print(line)\n",
    "                errors += 1\n",
    "            data.append(clean_data)\n",
    "            if len(data) >= max_to_import:\n",
    "                break\n",
    "\n",
    "    df = pl.DataFrame(data)\n",
    "    print(f\"Loaded: {df.shape[0]:,} rows, {df.shape[1]:,} columns. Excluded {errors} many errors\")\n",
    "\n",
    "    # Additional safety checks: replace any NBSP remaining in the DataFrame itself\n",
    "    # Just in case something slipped through.\n",
    "    # We'll apply a replacement to all string columns.\n",
    "    string_cols = [c for c, dt in zip(df.columns, df.dtypes) if dt in (pl.Utf8, pl.Object)]\n",
    "    for col in string_cols:\n",
    "        # Replace NBSP and HTML entities again at DataFrame level\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).str.replace(\"\\u00a0\", \" \")\n",
    "                       .str.replace(\"\\xa0\", \" \")\n",
    "                       .str.replace(\"&nbsp;\", \" \")\n",
    "                       .str.replace(\"NBSP\", \" \")\n",
    "        )\n",
    "    \n",
    "    # Double check for NBSP characters in the text field (if it exists)\n",
    "    if \"text\" in df.columns:\n",
    "        # Convert to Python strings and check\n",
    "        sample_text = df[\"text\"].head().to_list()\n",
    "        \n",
    "        # Check if NBSP still present\n",
    "        nbsp_found = any(\"\\u00a0\" in t or \"&nbsp;\" in t for t in sample_text if isinstance(t, str))\n",
    "        \n",
    "        if nbsp_found:\n",
    "            print(\"Warning: NBSP characters found in sample after cleanup!\")\n",
    "        else:\n",
    "            print(\"No NBSP found in sample text after cleanup.\")\n",
    "\n",
    "    return df"
   ],
   "id": "fc5189260ba1df35",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:19.735386Z",
     "start_time": "2024-12-09T17:06:11.616727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reviews = load_json_to_dataframe(path_reviews, 1_000_000)\n",
    "# businesses = load_json_to_dataframe(path_businesses, 9_999)\n",
    "# tips = load_json_to_dataframe(path_tips, 9_999)\n",
    "# checkins = load_json_to_dataframe(path_checkins, 9_999)"
   ],
   "id": "c0ec9d3cd5f3d3f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1,000,000 rows, 9 columns. Excluded 0 many errors\n",
      "No NBSP found in sample text after cleanup.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d5905c5ad509f21f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:21.577923Z",
     "start_time": "2024-12-09T17:06:21.574280Z"
    }
   },
   "cell_type": "code",
   "source": "reviews.head()",
   "id": "bb8b1134cdc0063c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 9)\n",
       "┌──────────────┬──────────────┬─────────────┬───────┬───┬───────┬──────┬─────────────┬─────────────┐\n",
       "│ review_id    ┆ user_id      ┆ business_id ┆ stars ┆ … ┆ funny ┆ cool ┆ text        ┆ date        │\n",
       "│ ---          ┆ ---          ┆ ---         ┆ ---   ┆   ┆ ---   ┆ ---  ┆ ---         ┆ ---         │\n",
       "│ str          ┆ str          ┆ str         ┆ f64   ┆   ┆ i64   ┆ i64  ┆ str         ┆ str         │\n",
       "╞══════════════╪══════════════╪═════════════╪═══════╪═══╪═══════╪══════╪═════════════╪═════════════╡\n",
       "│ KU_O5udG6zpx ┆ mh_-eMZ6K5RL ┆ XQfwVwDr-v0 ┆ 3.0   ┆ … ┆ 0     ┆ 0    ┆ If you      ┆ 2018-07-07  │\n",
       "│ Og-VcAEodg   ┆ WhZyISBhwA   ┆ ZS3_CbbE5Xw ┆       ┆   ┆       ┆      ┆ decide to   ┆ 22:09:11    │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ eat here,   ┆             │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ jus…        ┆             │\n",
       "│ BiTunyQ73aT9 ┆ OyoGAe7OKpv6 ┆ 7ATYjTIgM3j ┆ 5.0   ┆ … ┆ 0     ┆ 1    ┆ I've taken  ┆ 2012-01-03  │\n",
       "│ WBnpR9DZGw   ┆ SyGZT5g77Q   ┆ Ult4UM3IypQ ┆       ┆   ┆       ┆      ┆ a lot of    ┆ 15:28:18    │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ spin class… ┆             │\n",
       "│ saUsX_uimxRl ┆ 8g_iMtfSiwik ┆ YjUWPpI6HXG ┆ 3.0   ┆ … ┆ 0     ┆ 0    ┆ Family      ┆ 2014-02-05  │\n",
       "│ CVr67Z4Jig   ┆ VnbP2etR0A   ┆ 530lwP-fb2A ┆       ┆   ┆       ┆      ┆ diner. Had  ┆ 20:30:30    │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ the buffet. ┆             │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ …           ┆             │\n",
       "│ AqPFMleE6RsU ┆ _7bHUi9Uuf5_ ┆ kxX2SOes4o- ┆ 5.0   ┆ … ┆ 0     ┆ 1    ┆ Wow!        ┆ 2015-01-04  │\n",
       "│ 23_auESxiA   ┆ _HHc_Q8guQ   ┆ D3ZQBkiMRfA ┆       ┆   ┆       ┆      ┆ Yummy,      ┆ 00:01:03    │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ different,  ┆             │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ delic…      ┆             │\n",
       "│ Sx8TMOWLNuJB ┆ bcjbaE6dDog4 ┆ e4Vwtrqf-wp ┆ 4.0   ┆ … ┆ 0     ┆ 1    ┆ Cute        ┆ 2017-01-14  │\n",
       "│ Wer-0pcmoA   ┆ jkNY91ncLQ   ┆ JfwesgvdgxQ ┆       ┆   ┆       ┆      ┆ interior    ┆ 20:54:15    │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ and owner   ┆             │\n",
       "│              ┆              ┆             ┆       ┆   ┆       ┆      ┆ (?) ga…     ┆             │\n",
       "└──────────────┴──────────────┴─────────────┴───────┴───┴───────┴──────┴─────────────┴─────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review_id</th><th>user_id</th><th>business_id</th><th>stars</th><th>useful</th><th>funny</th><th>cool</th><th>text</th><th>date</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;KU_O5udG6zpxOg-VcAEodg&quot;</td><td>&quot;mh_-eMZ6K5RLWhZyISBhwA&quot;</td><td>&quot;XQfwVwDr-v0ZS3_CbbE5Xw&quot;</td><td>3.0</td><td>0</td><td>0</td><td>0</td><td>&quot;If you decide to eat here, jus…</td><td>&quot;2018-07-07 22:09:11&quot;</td></tr><tr><td>&quot;BiTunyQ73aT9WBnpR9DZGw&quot;</td><td>&quot;OyoGAe7OKpv6SyGZT5g77Q&quot;</td><td>&quot;7ATYjTIgM3jUlt4UM3IypQ&quot;</td><td>5.0</td><td>1</td><td>0</td><td>1</td><td>&quot;I&#x27;ve taken a lot of spin class…</td><td>&quot;2012-01-03 15:28:18&quot;</td></tr><tr><td>&quot;saUsX_uimxRlCVr67Z4Jig&quot;</td><td>&quot;8g_iMtfSiwikVnbP2etR0A&quot;</td><td>&quot;YjUWPpI6HXG530lwP-fb2A&quot;</td><td>3.0</td><td>0</td><td>0</td><td>0</td><td>&quot;Family diner. Had the buffet. …</td><td>&quot;2014-02-05 20:30:30&quot;</td></tr><tr><td>&quot;AqPFMleE6RsU23_auESxiA&quot;</td><td>&quot;_7bHUi9Uuf5__HHc_Q8guQ&quot;</td><td>&quot;kxX2SOes4o-D3ZQBkiMRfA&quot;</td><td>5.0</td><td>1</td><td>0</td><td>1</td><td>&quot;Wow!&nbsp;&nbsp;Yummy, different,&nbsp;&nbsp;delic…</td><td>&quot;2015-01-04 00:01:03&quot;</td></tr><tr><td>&quot;Sx8TMOWLNuJBWer-0pcmoA&quot;</td><td>&quot;bcjbaE6dDog4jkNY91ncLQ&quot;</td><td>&quot;e4Vwtrqf-wpJfwesgvdgxQ&quot;</td><td>4.0</td><td>1</td><td>0</td><td>1</td><td>&quot;Cute interior and owner (?) ga…</td><td>&quot;2017-01-14 20:54:15&quot;</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "users = load_json_to_dataframe(path_users, 9_999)",
   "id": "a551eccc23edd4de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# businesses.head(2)",
   "id": "9210efa04983cb9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# tips.head(2)",
   "id": "78da6dfc436727f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# checkins.head(2)",
   "id": "b32d572e6fcb6f86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "users.head(2)",
   "id": "ec665aba653837ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction with embeddings\n",
   "id": "c2f9cce4b1fe997e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:26.841215Z",
     "start_time": "2024-12-09T17:06:26.837528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = reviews.select(pl.col(\"text\", \"stars\"))\n",
    "df = df.with_columns(pl.col(\"stars\").cast(pl.Int64))"
   ],
   "id": "c31978485b391c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:28.172733Z",
     "start_time": "2024-12-09T17:06:28.170371Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "31c715d3fcca7a35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ text                            ┆ stars │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i64   │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ If you decide to eat here, jus… ┆ 3     │\n",
       "│ I've taken a lot of spin class… ┆ 5     │\n",
       "│ Family diner. Had the buffet. … ┆ 3     │\n",
       "│ Wow!  Yummy, different,  delic… ┆ 5     │\n",
       "│ Cute interior and owner (?) ga… ┆ 4     │\n",
       "└─────────────────────────────────┴───────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>stars</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;If you decide to eat here, jus…</td><td>3</td></tr><tr><td>&quot;I&#x27;ve taken a lot of spin class…</td><td>5</td></tr><tr><td>&quot;Family diner. Had the buffet. …</td><td>3</td></tr><tr><td>&quot;Wow!&nbsp;&nbsp;Yummy, different,&nbsp;&nbsp;delic…</td><td>5</td></tr><tr><td>&quot;Cute interior and owner (?) ga…</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# unicode sanity checks\n",
    "\n",
    "# df[\"text\"][3]\n",
    "\n",
    "# for idx, val in enumerate(df[\"text\"].head().to_list()):\n",
    "#     if \"\\u00a0\" in val or \"&nbsp;\" in val:\n",
    "#         print(f\"NBSP still found in row {idx}: {repr(val)}\")\n",
    "#     else:\n",
    "#         print(f\"No NBSP in row {idx}.\")\n",
    "\n",
    "# text_value = df[\"text\"][3]\n",
    "# for idx, char in enumerate(text_value):\n",
    "#     print(idx, char, ord(char), f\"\\\\u{ord(char):04x}\")"
   ],
   "id": "cde24d2758951bbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:33.729112Z",
     "start_time": "2024-12-09T17:06:33.717302Z"
    }
   },
   "cell_type": "code",
   "source": "df.group_by(pl.col(\"stars\")).len()",
   "id": "911651d35fb74358",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────┬────────┐\n",
       "│ stars ┆ len    │\n",
       "│ ---   ┆ ---    │\n",
       "│ i64   ┆ u32    │\n",
       "╞═══════╪════════╡\n",
       "│ 2     ┆ 77912  │\n",
       "│ 4     ┆ 221897 │\n",
       "│ 3     ┆ 102954 │\n",
       "│ 1     ┆ 138625 │\n",
       "│ 5     ┆ 458612 │\n",
       "└───────┴────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>stars</th><th>len</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>2</td><td>77912</td></tr><tr><td>4</td><td>221897</td></tr><tr><td>3</td><td>102954</td></tr><tr><td>1</td><td>138625</td></tr><tr><td>5</td><td>458612</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:06:42.765782Z",
     "start_time": "2024-12-09T17:06:42.585476Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5b0419e8ba4ddfee",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T17:15:30.234744Z",
     "start_time": "2024-12-09T17:11:42.235093Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c4f18ad62d858f6d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 31250/31250 [03:33<00:00, 146.18it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "1c1c0d0887dd84fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# model def \n",
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "        super(SimpleRegressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 5)  # 5 outputs for probabilities\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)  # logits\n",
    "        return out\n",
    "\n",
    "input_dim = embeddings.shape[1]\n",
    "model = SimpleRegressor(input_dim)\n",
    "model = model.to(\"cuda\")  # or \"cuda\" if available"
   ],
   "id": "cc9542c5396c95db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# loss\n",
    "def emd_loss(y_pred, y_true):\n",
    "    # y_pred: (batch, 5) logits\n",
    "    # y_true: (batch, 5) one-hot vectors\n",
    "    p = torch.softmax(y_pred, dim=1)\n",
    "    P = torch.cumsum(p, dim=1)\n",
    "    Q = torch.cumsum(y_true, dim=1)\n",
    "    emd = torch.sum(torch.abs(P - Q), dim=1)  # sum over the five dimensions\n",
    "    return torch.mean(emd)"
   ],
   "id": "cd0f3571aff3d8b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # train\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# num_epochs = 5  # for demonstration, adjust as needed\n",
    "# \n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "#     for batch_x, batch_y in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         pred = model(batch_x)\n",
    "#         loss = emd_loss(pred, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item() * len(batch_x)\n",
    "#     train_loss /= len(train_loader.dataset)\n",
    "#     \n",
    "#     # Evaluate on test set\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_x, batch_y in test_loader:\n",
    "#             pred = model(batch_x)\n",
    "#             loss = emd_loss(pred, batch_y)\n",
    "#             test_loss += loss.item() * len(batch_x)\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     \n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}\")"
   ],
   "id": "e601df8c1597efbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 5  # for demonstration, adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_x = batch_x.to(\"cuda\")\n",
    "        batch_y = batch_y.to(\"cuda\")\n",
    "        \n",
    "        pred = model(batch_x)\n",
    "        loss = emd_loss(pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(batch_x)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            pred = model(batch_x)\n",
    "            loss = emd_loss(pred, batch_y)\n",
    "            test_loss += loss.item() * len(batch_x)\n",
    "    \n",
    "            # Compute hit rate\n",
    "            # y_pred_classes: argmax of predictions\n",
    "            # y_true_classes: argmax of one-hot labels\n",
    "            y_pred_classes = torch.argmax(torch.softmax(pred, dim=1), dim=1)\n",
    "            y_true_classes = torch.argmax(batch_y, dim=1)\n",
    "    \n",
    "            correct += (y_pred_classes == y_true_classes).sum().item()\n",
    "            total += len(batch_x)\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    hit_rate = correct / total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Hit Rate: {hit_rate:.4f}\")    "
   ],
   "id": "28ee4e9cd47aedb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# eval\n",
    "new_texts = [\"This product was great!\", \"Not what I expected...\"]\n",
    "new_embeddings = embedder.encode(new_texts, convert_to_numpy=True)\n",
    "new_embeddings_t = torch.tensor(new_embeddings, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    logits = model(new_embeddings_t)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    predicted_stars = torch.argmax(probs, dim=1) + 1\n",
    "    print(\"Predicted stars:\", predicted_stars.tolist())"
   ],
   "id": "1d2972872a61d695",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

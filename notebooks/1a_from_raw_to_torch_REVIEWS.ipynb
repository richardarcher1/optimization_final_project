{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T19:02:19.249623Z",
     "start_time": "2024-12-09T19:02:18.532130Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import json \n",
    "# import pandas as pd\n",
    "# import polars as pl\n",
    "import unicodedata\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "from torch.utils.data import Dataset # , DataLoader\n",
    "import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:02:19.416081Z",
     "start_time": "2024-12-09T19:02:19.414428Z"
    }
   },
   "cell_type": "code",
   "source": "path = \"../data/0_raw/yelp-dataset/versions/4/\"",
   "id": "4afed51245e03175",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:02:20.104849Z",
     "start_time": "2024-12-09T19:02:20.103118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_reviews = path+\"yelp_academic_dataset_review.json\"\n",
    "# path_businesses = path+\"yelp_academic_dataset_business.json\"\n",
    "# path_tips = path+\"yelp_academic_dataset_tip.json\"\n",
    "# path_checkins = path+\"yelp_academic_dataset_checkin.json\"\n",
    "path_users = path+\"yelp_academic_dataset_user.json\""
   ],
   "id": "c64b6b785ee0e0ca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:02:20.933288Z",
     "start_time": "2024-12-09T19:02:20.929866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_json_to_dataframe(json_path, max_to_import=999_999_999):\n",
    "    \"\"\"\n",
    "    Load a JSON file with line-delimited JSON objects into a Polars DataFrame, \n",
    "    with an option to limit the number of rows imported. Convert all spaces to \n",
    "    proper spaces and ensure no NBSP remain.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_line(line):\n",
    "        # Normalize unicode to ensure consistency in whitespace representations\n",
    "        line = unicodedata.normalize(\"NFKC\", line)\n",
    "        \n",
    "        # Replace various forms of non-breaking spaces and related entities with a normal space\n",
    "        # '\\u00a0' is the standard NBSP unicode character\n",
    "        # '&nbsp;' is an HTML entity that may appear\n",
    "        # We'll also remove literal 'NBSP' if present as text.\n",
    "        line = line.replace(\"\\u00a0\", \" \")\n",
    "        line = line.replace(\"\\xa0\", \" \")  # Sometimes NBSP is represented like this\n",
    "        line = line.replace(\"&nbsp;\", \" \")\n",
    "        line = line.replace(\"NBSP\", \" \")\n",
    "        \n",
    "        return line\n",
    "\n",
    "    # Read and clean each line before parsing\n",
    "    data = []\n",
    "    errors = 0\n",
    "    with open(json_path, 'r', encoding='utf-8') as data_file:\n",
    "        # for line in data_file:\n",
    "        for line in tqdm(data_file, desc=\"Processing lines\"):\n",
    "            try:\n",
    "                clean_data = json.loads(clean_line(line))\n",
    "            except:\n",
    "                # print(line)\n",
    "                errors += 1\n",
    "            data.append(clean_data)\n",
    "            if len(data) >= max_to_import:\n",
    "                break\n",
    "\n",
    "    df = pl.DataFrame(data)\n",
    "    print(f\"Loaded: {df.shape[0]:,} rows, {df.shape[1]:,} columns. Excluded {errors} many errors\")\n",
    "\n",
    "    # Additional safety checks: replace any NBSP remaining in the DataFrame itself\n",
    "    # Just in case something slipped through.\n",
    "    # We'll apply a replacement to all string columns.\n",
    "    string_cols = [c for c, dt in zip(df.columns, df.dtypes) if dt in (pl.Utf8, pl.Object)]\n",
    "    for col in string_cols:\n",
    "        # Replace NBSP and HTML entities again at DataFrame level\n",
    "        df = df.with_columns(\n",
    "            pl.col(col).str.replace(\"\\u00a0\", \" \")\n",
    "                       .str.replace(\"\\xa0\", \" \")\n",
    "                       .str.replace(\"&nbsp;\", \" \")\n",
    "                       .str.replace(\"NBSP\", \" \")\n",
    "        )\n",
    "    \n",
    "    # Double check for NBSP characters in the text field (if it exists)\n",
    "    if \"text\" in df.columns:\n",
    "        # Convert to Python strings and check\n",
    "        sample_text = df[\"text\"].head().to_list()\n",
    "        \n",
    "        # Check if NBSP still present\n",
    "        nbsp_found = any(\"\\u00a0\" in t or \"&nbsp;\" in t for t in sample_text if isinstance(t, str))\n",
    "        \n",
    "        if nbsp_found:\n",
    "            print(\"Warning: NBSP characters found in sample after cleanup!\")\n",
    "        else:\n",
    "            print(\"No NBSP found in sample text after cleanup.\")\n",
    "\n",
    "    return df"
   ],
   "id": "b4c2d08f8c6a35b2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:02:29.857630Z",
     "start_time": "2024-12-09T19:02:22.417073Z"
    }
   },
   "cell_type": "code",
   "source": "reviews = load_json_to_dataframe(path_reviews, 1_000_000)",
   "id": "64367d1c91d0d969",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing lines: 999999it [00:03, 293769.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1,000,000 rows, 9 columns. Excluded 0 many errors\n",
      "No NBSP found in sample text after cleanup.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:02:32.717038Z",
     "start_time": "2024-12-09T19:02:32.712403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = reviews.select(pl.col(\"text\", \"stars\"))\n",
    "df = df.with_columns(pl.col(\"stars\").cast(pl.Int8))"
   ],
   "id": "7b71600e236f91da",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:05:21.738128Z",
     "start_time": "2024-12-09T19:05:21.396165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set_proportion = 0.85\n",
    "test_set_proportion = 0.149\n",
    "validation_set_proportion = 0.001\n",
    "n = df.shape[0]\n",
    "\n",
    "# Define the probabilities for each split\n",
    "split_probabilities = [train_set_proportion, test_set_proportion, validation_set_proportion]\n",
    "\n",
    "# Assign split labels\n",
    "train_test_validation_split = np.random.choice(\n",
    "    [1, 2, 3],  # 1: train, 2: test, 3: validation\n",
    "    size=n,\n",
    "    p=split_probabilities\n",
    ")\n",
    "\n",
    "# Add split column to dataframe\n",
    "df = df.with_columns(pl.Series(train_test_validation_split).alias(\"split\"))\n",
    "\n",
    "# Create separate datasets\n",
    "df_train = df.filter(pl.col(\"split\") == 1).select(pl.col(\"text\", \"stars\"))\n",
    "df_test = df.filter(pl.col(\"split\") == 2).select(pl.col(\"text\", \"stars\"))\n",
    "df_validation = df.filter(pl.col(\"split\") == 3).select(pl.col(\"text\", \"stars\"))\n",
    "\n",
    "# Save datasets to CSV\n",
    "df_train.write_csv(\"../data/1_train_test_split/df_train.csv\")\n",
    "df_test.write_csv(\"../data/1_train_test_split/df_test.csv\")\n",
    "df_validation.write_csv(\"../data/1_train_test_split/df_validation.csv\")\n"
   ],
   "id": "9c136bb29b2a102a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "53f5a27b3f196fae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6098b4695b9c8ff0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "43e6c2e6c1c425c0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

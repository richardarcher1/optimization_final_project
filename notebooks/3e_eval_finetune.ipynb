{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.029817Z",
     "start_time": "2024-12-12T00:45:48.371764Z"
    }
   },
   "source": [
    "# standard python imports\n",
    "import os\n",
    "# import pandas as pd\n",
    "import torch\n",
    "\n",
    "# huggingface libraries\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    # HfArgumentParser,\n",
    "    # TrainingArguments,\n",
    "    pipeline,\n",
    "    # logging,\n",
    "    LlamaForCausalLM\n",
    ")\n",
    "from peft import (\n",
    "#     LoraConfig,\n",
    "    PeftModel,\n",
    "#     prepare_model_for_kbit_training,\n",
    "#     get_peft_model,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "# from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "# import wandb\n",
    "\n",
    "import polars as pl\n",
    "# import pandas as pd\n",
    "\n",
    "from transformers.pipelines.pt_utils import KeyDataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.033940Z",
     "start_time": "2024-12-12T00:45:50.032312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_prompt(review):\n",
    "    system_prompt = f\"You read Yelp reviews and return a number (1, 2, 3, 4, or 5) that represents your besst guess of the number of star ratings that were given by that reviewer. Return just the number 1, 2, 3, 4, or 5, with no context, explanation, or special symbols.\"\n",
    "    prompt = f\"Here is the review to evaluate: [[[{review}]]]. Remember, you read Yelp reviews and return a number (1, 2, 3, 4, or 5) that represents your besst guess of the number of star ratings that were given by that reviewer. Return just the number 1, 2, 3, 4, or 5, with no context, explanation, or special symbols.\"\n",
    "        \n",
    "    return system_prompt, prompt"
   ],
   "id": "1a69d01046c63b8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.086866Z",
     "start_time": "2024-12-12T00:45:50.082147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_train = pl.read_csv(\"../data/1_train_test_split/df_train.csv\")\n",
    "df_val = pl.read_csv(\"../data/1_train_test_split/df_validation.csv\")"
   ],
   "id": "dd217abf75548e67",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.133421Z",
     "start_time": "2024-12-12T00:45:50.125838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lst_system_prompt, lst_prompt = [], []\n",
    "for row in df_val.iter_rows(named=True):\n",
    "    system_prompt, prompt = create_prompt(row[\"text\"])\n",
    "    lst_system_prompt.append(system_prompt)\n",
    "    lst_prompt.append(prompt)\n",
    "df_val = df_val.with_columns(pl.Series(lst_system_prompt).alias(\"system_prompt\"), pl.Series(lst_prompt).alias(\"prompt\"))"
   ],
   "id": "58e55d8b46dc33ac",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.186420Z",
     "start_time": "2024-12-12T00:45:50.178549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = df_val[\"text\"].to_list()\n",
    "test_labels = df_val[\"stars\"].to_list()\n",
    "\n",
    "data_ = Dataset.from_polars(df_val)"
   ],
   "id": "19ac07b2242dd0af",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.223423Z",
     "start_time": "2024-12-12T00:45:50.222238Z"
    }
   },
   "cell_type": "code",
   "source": "# !ls /home/richardarcher/Dropbox/Sci24_LLM_Polarization/project_/weights_local/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659",
   "id": "529877df60b0dca",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.266340Z",
     "start_time": "2024-12-12T00:45:50.265158Z"
    }
   },
   "cell_type": "code",
   "source": "base_model = \"/home/richardarcher/Dropbox/Sci24_LLM_Polarization/project_/weights_local/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659\"",
   "id": "37e6d55334f5b694",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HERE",
   "id": "55b6ef50bc876a01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.309403Z",
     "start_time": "2024-12-12T00:45:50.308178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PATH_adapter_custom_weights = \"../weights/sft/run00/checkpoint-1000/\"\n",
    "# PATH_adapter_custom_weights = \"../weights/sft/run01/checkpoint-1000/\"\n",
    "# PATH_adapter_custom_weights = \"../weights/sft/run01/checkpoint-10000/\"\n",
    "# PATH_adapter_custom_weights = \"../weights/sft/run01/checkpoint-20000/\"\n",
    "PATH_adapter_custom_weights = \"../weights/sft/run01/checkpoint-29000/\""
   ],
   "id": "3b16b06ddeb2a463",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:50.541890Z",
     "start_time": "2024-12-12T00:45:50.351533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model,\n",
    "    tokenizer_file=os.path.join(base_model, 'tokenizer.json'),\n",
    "    tokenizer_config_file=os.path.join(base_model, 'tokenizer_config.json'),\n",
    "    special_tokens_map_file=os.path.join(base_model, 'special_tokens_map.json'),\n",
    "    trust_remote_code=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = 'left'"
   ],
   "id": "b30b22b7c82e8852",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:54.794682Z",
     "start_time": "2024-12-12T00:45:50.551784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    # load_in_8bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Match input dtype\n",
    "\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(base_model, quantization_config=nf4_config)"
   ],
   "id": "c277d54a99697aaa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7478ed97b1674a189222347ae8471d22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:55.986898Z",
     "start_time": "2024-12-12T00:45:54.806758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = PeftModel.from_pretrained(model, PATH_adapter_custom_weights)\n",
    "model = model.merge_and_unload() # This line merges the weights"
   ],
   "id": "b093843d6a7a734b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richardarcher/miniconda3/envs/gofaster00/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:56.000460Z",
     "start_time": "2024-12-12T00:45:55.999163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not tokenizer.pad_token_id:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ],
   "id": "47304be292554fd5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:56.043362Z",
     "start_time": "2024-12-12T00:45:56.041653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_header(text, K_times):\n",
    "    for _ in range(K_times):\n",
    "        if \"<|end_header_id|>\" in text:\n",
    "            text = text.split(\"<|end_header_id|>\", 1)[1]\n",
    "    return text"
   ],
   "id": "6f469e982841cc6a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:56.087936Z",
     "start_time": "2024-12-12T00:45:56.086083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_format_chat_template(tokenizer):\n",
    "    def format_chat_template(row):\n",
    "        row_json = [{\"role\": \"system\", \"content\": row[\"system_prompt\"]},\n",
    "                    {\"role\": \"user\", \"content\": row[\"prompt\"]}]\n",
    "\n",
    "        # row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "        row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False, add_generation_prompt=True)\n",
    "        return row\n",
    "    return format_chat_template"
   ],
   "id": "7a224b5d123ec1cd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:56.131462Z",
     "start_time": "2024-12-12T00:45:56.129991Z"
    }
   },
   "cell_type": "code",
   "source": "batch_size = 8",
   "id": "83a81c70c7841d9c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:56.176007Z",
     "start_time": "2024-12-12T00:45:56.174057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    # torch_dtype=torch.float32,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    batch_size=batch_size, # CHANGE TO FOUR IF TOO SLOW\n",
    "    max_new_tokens=5,\n",
    ")"
   ],
   "id": "6757cf10b573d793",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:45:56.326302Z",
     "start_time": "2024-12-12T00:45:56.218073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_ = data_.map(\n",
    "    create_format_chat_template(tokenizer)\n",
    ")"
   ],
   "id": "3b8f2678c135fa66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1018 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61e5626594f24460865c2722923a9808"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:47:24.446112Z",
     "start_time": "2024-12-12T00:45:56.337804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = []\n",
    "ix = 0 \n",
    "for out in pipe(KeyDataset(data_, \"text\")):\n",
    "    ix = ix + 1\n",
    "    # print(ix)\n",
    "    if ix % batch_size == 0:\n",
    "        print(f\"{ix}/{data_.shape[0]}\")\n",
    "    \n",
    "    cleaned_text = remove_header(out[0][\"generated_text\"], 3).strip()\n",
    "    res.append(cleaned_text)"
   ],
   "id": "72f3f866c60f5fde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/1018\n",
      "16/1018\n",
      "24/1018\n",
      "32/1018\n",
      "40/1018\n",
      "48/1018\n",
      "56/1018\n",
      "64/1018\n",
      "72/1018\n",
      "80/1018\n",
      "88/1018\n",
      "96/1018\n",
      "104/1018\n",
      "112/1018\n",
      "120/1018\n",
      "128/1018\n",
      "136/1018\n",
      "144/1018\n",
      "152/1018\n",
      "160/1018\n",
      "168/1018\n",
      "176/1018\n",
      "184/1018\n",
      "192/1018\n",
      "200/1018\n",
      "208/1018\n",
      "216/1018\n",
      "224/1018\n",
      "232/1018\n",
      "240/1018\n",
      "248/1018\n",
      "256/1018\n",
      "264/1018\n",
      "272/1018\n",
      "280/1018\n",
      "288/1018\n",
      "296/1018\n",
      "304/1018\n",
      "312/1018\n",
      "320/1018\n",
      "328/1018\n",
      "336/1018\n",
      "344/1018\n",
      "352/1018\n",
      "360/1018\n",
      "368/1018\n",
      "376/1018\n",
      "384/1018\n",
      "392/1018\n",
      "400/1018\n",
      "408/1018\n",
      "416/1018\n",
      "424/1018\n",
      "432/1018\n",
      "440/1018\n",
      "448/1018\n",
      "456/1018\n",
      "464/1018\n",
      "472/1018\n",
      "480/1018\n",
      "488/1018\n",
      "496/1018\n",
      "504/1018\n",
      "512/1018\n",
      "520/1018\n",
      "528/1018\n",
      "536/1018\n",
      "544/1018\n",
      "552/1018\n",
      "560/1018\n",
      "568/1018\n",
      "576/1018\n",
      "584/1018\n",
      "592/1018\n",
      "600/1018\n",
      "608/1018\n",
      "616/1018\n",
      "624/1018\n",
      "632/1018\n",
      "640/1018\n",
      "648/1018\n",
      "656/1018\n",
      "664/1018\n",
      "672/1018\n",
      "680/1018\n",
      "688/1018\n",
      "696/1018\n",
      "704/1018\n",
      "712/1018\n",
      "720/1018\n",
      "728/1018\n",
      "736/1018\n",
      "744/1018\n",
      "752/1018\n",
      "760/1018\n",
      "768/1018\n",
      "776/1018\n",
      "784/1018\n",
      "792/1018\n",
      "800/1018\n",
      "808/1018\n",
      "816/1018\n",
      "824/1018\n",
      "832/1018\n",
      "840/1018\n",
      "848/1018\n",
      "856/1018\n",
      "864/1018\n",
      "872/1018\n",
      "880/1018\n",
      "888/1018\n",
      "896/1018\n",
      "904/1018\n",
      "912/1018\n",
      "920/1018\n",
      "928/1018\n",
      "936/1018\n",
      "944/1018\n",
      "952/1018\n",
      "960/1018\n",
      "968/1018\n",
      "976/1018\n",
      "984/1018\n",
      "992/1018\n",
      "1000/1018\n",
      "1008/1018\n",
      "1016/1018\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:47:24.464420Z",
     "start_time": "2024-12-12T00:47:24.463034Z"
    }
   },
   "cell_type": "code",
   "source": "res_int = [int(i) for i in res]",
   "id": "d2eb106b7339e996",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:47:24.506060Z",
     "start_time": "2024-12-12T00:47:24.504255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "right, total = 0, 0\n",
    "for pred, actual in zip(res_int, test_labels):\n",
    "    if pred==actual:\n",
    "        right += 1\n",
    "    total += 1\n",
    "\n",
    "print(right/total)"
   ],
   "id": "62c003e68002c8dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7416502946954814\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:47:24.604181Z",
     "start_time": "2024-12-12T00:47:24.602562Z"
    }
   },
   "cell_type": "code",
   "source": "df_val = df_val.with_columns(pl.Series(res_int).alias(\"8b_quant_prediction\"))",
   "id": "c2e62ef238a608f7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T00:47:24.650331Z",
     "start_time": "2024-12-12T00:47:24.645940Z"
    }
   },
   "cell_type": "code",
   "source": "df_val.write_csv(\"../data/3_outputs/8b_quantized_predictions_for_eval_set_check20000.csv\")",
   "id": "7d54d132fafc5ed3",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
